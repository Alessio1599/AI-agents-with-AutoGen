{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {},
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693467e",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent( # class\n",
    "    name=\"chatbot\", # name of the agent\n",
    "    llm_config=llm_config, # the agent will use the LLM model to generate responses\n",
    "    human_input_mode=\"NEVER\", # the agent will never seek for human input\n",
    "    # \"ALWAYS\" - the agent will always seek for human input before generating a response\n",
    ")\n",
    "# Basic set-up for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Ask the agent to generate a response to the user's message\n",
    "reply = agent.generate_reply( # we call the generate_reply method of the agent\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Even if we asked to repeat the joke, the agent will not repeat it\n",
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {},
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained.\n",
    "\n",
    "If we don't define the system_message the agent will perform as a generic purpose assistant agent. Using the system message we customize the behavior of the agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "# First agent\n",
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Second agent\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {},
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2, # two turns of the conversation and then the chat ends\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {},
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)\n",
    "# we can see the chat history, all the messages exchanged between the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.cost)\n",
    "# the cost of the chat, expressed in tokens: completion tokens + prompt tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Summary of the chat\n",
    "# In this case, the summary is the last message of the chat, but we can also provide a custom summary -> summary_method\n",
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    "    # essentially after the conversion ends, we will call a LLM to summarize the conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)\n",
    "# Better summary of the chat, with respect to the last message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {},
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions.\n",
    "\n",
    "The **termination message** is a bolean function, which takes a message as input and returns a true or false\n",
    "\n",
    "- Notice that also the system message was changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"], # boolean function\n",
    "    # if \"I gotta go\" is in the message, the conversation ends\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "# Both agents will end the conversation if the message contains \"I gotta go\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# cathy is sending a message, to know if joe remembers the last joke\n",
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
